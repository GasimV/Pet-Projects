---

# ğŸ¤– LangChain Chat with an LLM

This is a simple hands-on LangChain project to understand how to use LangChain with OpenAI models and Streamlit. It creates a lightweight chat interface where you can talk to an AI assistant.

---

## ğŸ”§ Features

- âœ… Chat with an OpenAI model using LangChain
- âœ… Built-in chat memory (session-based)
- âœ… Streamlit-powered web UI
- âœ… Modular and beginner-friendly

---

## ğŸ§  Tech Stack

- [LangChain](https://docs.langchain.com/) â€“ Framework for building LLM apps
- [OpenAI](https://platform.openai.com/) â€“ Language model provider
- [Streamlit](https://streamlit.io/) â€“ Web UI
- [Python dotenv](https://pypi.org/project/python-dotenv/) â€“ For API key management

---

## ğŸš€ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/GasimV/Pet_Projects/LangChain Chat with an LLM.git
cd "LangChain Chat with an LLM"
```

### 2. Install Dependencies

It's best to use a virtual environment:

```bash
python -m venv .venv
source .venv/bin/activate   # On Windows: .venv\Scripts\activate
```

Install:

```bash
pip install streamlit langchain langchain-openai python-dotenv
```

### 3. Set Up Your API Key

Create a `.env` file in the root of the project:

```
OPENAI_API_KEY=your_openai_api_key_here
```

You can get your key from https://platform.openai.com/account/api-keys

---

## ğŸ’¬ Run the App

```bash
streamlit run langchain_chat_app.py
```

Visit http://localhost:8501 in your browser.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ langchain_chat_app.py   # Main chat app
â”œâ”€â”€ .env                    # Your API key (not committed)
â”œâ”€â”€ README.md

```

---

## ğŸ§© Next Steps

- Add **memory** using `ConversationBufferMemory`
- Add **tools/agents** like calculator or web search
- Swap in **local models** (like DeepSeek, Ollama, Llama.cpp)
- Integrate **LangSmith** for tracing/debugging

---

## ğŸ“œ License

MIT â€” free for personal and commercial use.

---