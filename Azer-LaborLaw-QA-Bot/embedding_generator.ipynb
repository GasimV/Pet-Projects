{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b5f00b-8900-4c45-9a9c-1c712b97d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install google-generativeai\n",
    "# pip install faiss-cpu\n",
    "# pip install python-telegram-bot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618cab83-ff8f-4863-b1e4-5cc762bf785e",
   "metadata": {},
   "source": [
    "## Embeddings Yaradılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52cbb02f-5c65-43d7-97e9-9190eb818ec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings uğurla yaradıldı və saxlandı.\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import numpy as np\n",
    "import faiss\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# .env faylından API açarını yükləyək\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# API Key konfiqurasiyası\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "def create_embeddings():\n",
    "    with open('labor_law_chunks.json', 'r', encoding='utf-8') as f:\n",
    "        chunks = json.load(f)\n",
    "\n",
    "    # Mətnləri və metadatanı ayırırıq\n",
    "    texts = [item['content'] for item in chunks]\n",
    "    metadata = [item['metadata'] for item in chunks]\n",
    "    \n",
    "    # Google Gemini ilə embedding-lərin yaradılması\n",
    "    model = 'models/gemini-embedding-001'\n",
    "    result = genai.embed_content(model=model, content=texts, task_type=\"RETRIEVAL_DOCUMENT\")\n",
    "    embeddings = result['embedding']\n",
    "\n",
    "    # FAISS indeksi yaratmaq\n",
    "    dimension = len(embeddings[0])\n",
    "    index = faiss.IndexFlatL2(dimension)\n",
    "    index.add(np.array(embeddings, dtype=np.float32))\n",
    "\n",
    "    # Faylların saxlanması\n",
    "    faiss.write_index(index, 'law_embeddings.faiss')\n",
    "    with open('chunks_for_retrieval.pkl', 'wb') as f:\n",
    "        pickle.dump({'texts': texts, 'metadata': metadata}, f)\n",
    "\n",
    "    print(\"Embeddings uğurla yaradıldı və saxlandı.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    create_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4998ef6-3cdd-49f3-90df-ea7dd9a27bae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (LLM)",
   "language": "python",
   "name": "llm-py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
