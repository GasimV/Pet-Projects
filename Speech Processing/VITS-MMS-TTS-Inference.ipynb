{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VitsModel, AutoTokenizer\n",
    "import torch\n",
    "import scipy\n",
    "\n",
    "model = VitsModel.from_pretrained(\"facebook/mms-tts-azj-script_latin\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/mms-tts-azj-script_latin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Salam! Nec…ôsiz? Asan xidm…ôt Caƒürƒ± M…ôrk…ôzin…ô z…ônƒü etdiyiniz √º√ß√ºn t…ô≈ü…ôkk√ºr edir…ôm. Buyurun sualƒ±nƒ±zƒ± verin.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(**inputs).waveform\n",
    "\n",
    "from IPython.display import Audio\n",
    "Audio(output.numpy(), rate=model.config.sampling_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üîç Why Those Warnings Appear\n",
    "1. **Training-specific components** (like `posterior_encoder`) exist in the checkpoint but are not used during inference.\n",
    "2. **Weight parametrizations** (e.g., LoRA layers or low-rank adapters) may be present but unused in standard inference mode.\n",
    "3. The model is still correctly generating waveforms ‚Äî the log just informs you that some weights were skipped or newly initialized, which is fine for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VitsModel, AutoTokenizer\n",
    "import torch\n",
    "import scipy\n",
    "\n",
    "model = VitsModel.from_pretrained(\"BHOSAI/SARA_TTS\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"BHOSAI/SARA_TTS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Salam! Nec…ôsiz? Asan xidm…ôt Caƒürƒ± M…ôrk…ôzin…ô z…ônƒü etdiyiniz √º√ß√ºn t…ô≈ü…ôkk√ºr edir…ôm. Buyurun sualƒ±nƒ±zƒ± verin.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(**inputs).waveform\n",
    "\n",
    "from IPython.display import Audio\n",
    "Audio(output.numpy(), rate=model.config.sampling_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (LLM)",
   "language": "python",
   "name": "llm-py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
