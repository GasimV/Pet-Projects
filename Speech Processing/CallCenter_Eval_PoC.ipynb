{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Transcribing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from stable_whisper import load_model\n",
    "\n",
    "# === SETTINGS ===\n",
    "root_dir = r\"...\"\n",
    "output_csv = r\"...\"  # ✅ Save here\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"🚀 Using device: {device}\")\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "model = load_model(\"large-v3\", device=device)\n",
    "\n",
    "# === HELPER FUNCTION ===\n",
    "def transcribe_audio_files(directory):\n",
    "    results = []\n",
    "\n",
    "    # Walk through all subdirectories\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            if filename.lower().endswith(\".wav\"):\n",
    "                filepath = os.path.join(root, filename)\n",
    "                print(f\"🎧 Transcribing: {filepath}\")\n",
    "\n",
    "                try:\n",
    "                    result = model.transcribe(filepath, language=\"az\")\n",
    "                    text = result.text.strip()  # ✅ Access object attribute, not dict\n",
    "\n",
    "                    if text:  # Skip empty transcriptions\n",
    "                        results.append([text, 1])  # Dummy label '1'\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Failed to transcribe {filename}: {e}\")\n",
    "    return results\n",
    "\n",
    "# === PROCESS ===\n",
    "transcriptions = transcribe_audio_files(root_dir)\n",
    "\n",
    "# === SAVE TO CSV ===\n",
    "if transcriptions:\n",
    "    os.makedirs(os.path.dirname(output_csv), exist_ok=True)  # ✅ Ensure output dir exists\n",
    "\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Transcription\", \"Label\"])  # Header\n",
    "        writer.writerows(transcriptions)\n",
    "\n",
    "    print(f\"✅ Transcriptions saved to {output_csv}\")\n",
    "else:\n",
    "    print(\"❌ No transcriptions were generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Single-Audio Transcrabing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "from stable_whisper import load_model\n",
    "\n",
    "# === SETTINGS ===\n",
    "audio_path = r\".wav\"\n",
    "output_csv = r\".csv\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"🚀 Using device: {device}\")\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "model = load_model(\"large-v3\", device=device)\n",
    "\n",
    "# === TRANSCRIBE SINGLE AUDIO ===\n",
    "try:\n",
    "    print(f\"🎧 Transcribing: {audio_path}\")\n",
    "    result = model.transcribe(audio_path, language=\"az\")\n",
    "    text = result.text.strip()\n",
    "\n",
    "    if text:\n",
    "        # === SAVE TO CSV ===\n",
    "        with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Transcription\", \"Label\"])  # Header\n",
    "            writer.writerow([text, 1])  # Dummy label\n",
    "\n",
    "        print(f\"✅ Transcription saved to {output_csv}\")\n",
    "    else:\n",
    "        print(\"⚠️ Transcription is empty.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during transcription: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\".csv\")\n",
    "display(df)\n",
    "print()\n",
    "display(df['Transcription'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Preprocessing & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\".csv\")\n",
    "display(df)\n",
    "print()\n",
    "display(df['Transcription'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df['Transcription'].iloc[97])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Lowercase the transcription text\n",
    "df[\"Transcription\"] = df[\"Transcription\"].str.lower()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save the new version to a separate CSV\n",
    "lowercased_file_path = r\"C:\\Pasha-PoC\\transcriptions.csv\"\n",
    "df.to_csv(lowercased_file_path, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = df.drop(index=13).reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Existing DataFrame\n",
    "df_transcripts = pd.read_csv(r\".csv\")\n",
    "\n",
    "# Pasting synthetic transcriptions here as a list of strings\n",
    "negative_samples = [\n",
    "    \"alo salam mən xaricə getmək üçün məhküm olmamağım barədə sənəd lazım olduğunu dedilər onu asan xidmətdən ala bilərəmmi salam xanım bu məsələyə biz baxmırıq deyəsən başqa yerdə verirlər belə sənədləri məncə siz notariusa yaxınlaşın amma deyiblər ki asan verir elə sənədi məncə əvvəllər verirdi indi dəyişib dəqiq bilmirəm bir dəqiqə zəhmət olmasa gözləyin alo səsiniz gəlmir zəifdi mən də yaxşı başa düşmürəm nə istəyirsiz sənədi bir də zəng edin bəlkə başqa əməkdaş cavab verə bilər\",\n",
    "    \"salam mənim şəxsiyyət vəsiqəmin müddəti keçib onu dəyişmək üçün nə etməliyəm salam buyurun sizə deyiblər biz dəyişirik deyəsən amma indi olmur elə şey bizdə yəni məlumat yoxdur məndə sənəd lazımdı amma nə sənədi bilmirəm dəqiq belə deyiblər sadəcə şəxsiyyət vəsiqəsi üçün adı dəyişib deyiblər onda notarius baxar deyəsən bizdə olmur sənəd vermə proseduru mənlik deyil zəhmət olmasa sonra zəng edin başqa əməkdaş bilər\",\n",
    "    \"salam mən ev üçün qeydiyyat arayışı almaq istəyirdim deyiblər asan xidmətdən alınır xanım o qeydiyyatla bağlı sənədlər biz vermirik məncə icra hakimiyyəti baxır ona yox mən konkret soruşuram siz vermirsinizsə deyin mən gedim başqa yerə baxın google yazın görün hardan verilir bizdə olmur bu gün o sənəd deyəsən çıxarılmır sistemdə problem var başqa sualınız varsa buyurun\",\n",
    "    \"alo salam mən mehkum olmamağım barədə arayış almaq istəyirəm çünki xaricə sənəd təqdim etməliyəm onu haradan ala bilərəm salam xanım dəqiq deyə bilmərəm vallah bizdə olmur məncə ədliyyə baxır o sənədlərə bəlkə ora gedəsiniz amma bu asan xidmət deyilmi siz verməlisiz axı məncə əvvəllər verilirdi indi necədi bilmirəm zəng edin soruşun ya başqa əməkdaşa yönləndirilsin bir dəqiqə alo səs kəsilir sonra zəng edin yaxşı\",\n",
    "    \"salam mən uşağın doğum haqqında şəhadətnaməsini almaq istəyirəm onlayn müraciət etmişdim amma alınmadı onu necə ala bilərəm salam bizdə o sistem işləmir deyəsən indi siz gedin notariusa bəlkə onlar kömək edə bilər onlayn alınmadısa bəlkə sistemdə nasazlıq var mən burada heç nə görə bilmirəm yəni siz deyirsiniz ki asan xidmət vermir məncə əvvəllər verirdi amma indi dəqiq bilmirəm sizə düzgün deyə bilmərəm\",\n",
    "    \"alo salam mən xaricə getmək üçün sənədlər toplamalıyam və məhküm olmamağım barədə arayış lazımdır onu necə ala bilərəm salam xanım belə sənədləri biz vermirik deyəsən yəni siz deyirsiniz heç vermirsiniz əvvəllər demişdilər sizdə olurdu indi yox deyəsən dəyişib sistemdə görünmür mənlik deyil siz gedin notariusa ora verə bilər amma dəqiq deyə bilmərəm yaxşı başa düşmədim indi siz verirsiniz ya yox yox yox deyəsən biz vermirik zəhmət olmasa sonra zəng edin bəlkə başqa əməkdaş bilər\",\n",
    "    \"salam mənə şəxsiyyət vəsiqəsi üçün qeydiyyat arayışı lazımdır internetdə yazılıb asan xidmətdən götürülür buyurun xanım mən bir şey bilmirəm o arayış bəlkə bələdiyyədən alınır yəni bu barədə məlumatım yoxdur bizdə olmur məncə amma siz deyirsiniz ki internetdə yazılıb bura verilir bəli amma mənlik deyil yəni sistemdə baxmıram mən indi sənədi hardan alım deyirsiniz heç bilmirsiniz zəng edin sabah soruşun mən dəqiq deyə bilmirəm\",\n",
    "    \"alo mən vərəsəliklə bağlı sənəd almaq istəyirdim buyurun salam xanım bu barədə heç məlumatım yoxdur vərəsəlik dediniz notarius baxır bizdə olmur sənədi necə ala bilərəm deyirlər bura yaxınlaşmaq lazımdır yox xanım o prosedur bizlik deyil deyəsən məhkəməyə aidiyyatı var zəng edin məhkəməyə bura belə şeylərlə məşğul olmur\",\n",
    "    \"salam mənim adım dəyişib şəxsiyyət vəsiqəsini dəyişmək istəyirəm hansı sənədlər lazımdır xanım siz yəqin qeydiyyat yerinə getməlisiniz bizdə olmur sənəd yəni məlumatım yoxdur belə şeylərlə biz baxmırıq əvvəlcə deyirdilər burdan alınır indi yox notarius bəlkə bilir zəhmət olmasa ora gedin mənlik deyil\",\n",
    "    \"salam mən xaricə sənəd göndərmək istəyirəm və sənədi təsdiqlətməliyəm buyurun amma xanım bu məsələ ilə məşğul olmuruq belə təsdiq üçün siz başqa yerdə təsdiq alın bəlkə konsulluğa zəng edin bu işlər bizlik deyil\",\n",
    "    \"salam mən şəxsiyyət vəsiqəmi itirmişəm və yeni sənəd almaq istəyirəm bu mümkünmü xanım itkin sənədlə bağlı biz məlumat vermirik polisə müraciət edin o sənəd bizlik deyil yəni siz heç nə edə bilmirsiniz yox xanım keçin bölməyə\",\n",
    "    \"alo salam mən ailə vəziyyətimlə bağlı sənəd istəyirəm deyiblər asan verir onu xanım mən bilmirəm belə şeylər üçün notarius var deyəsən ailə arayışları biz vermirik valla məlumatım yoxdur zəng edin başqa yerə\",\n",
    "    \"salam mənim uşağım üçün doğum şəhadətnaməsini bərpa etdirmək istəyirəm sistemdə görünmür xanım biz belə məlumatlara baxmırıq siz qeydiyyat şöbəsinə getməlisiniz bizdə olmur sənəd mən də buradan nə edə bilərəm\",\n",
    "    \"salam mən ev sənədimi təsdiqlətmək istəyirəm yəni alqı-satqı üçün lazımdır buyurun amma xanım bizdə belə şeylər olmur o sənədi siz ya notariusdan alın ya daşınmaz əmlak ofisinə yaxınlaşın asan baxmır bu tip şeylərə\",\n",
    "    \"salam mən özümə vasiqə çıxartmaq istəyirəm amma deyiblər bəzi sənədlər lazımdır nə lazımdır deyə bilərsiniz xanım bu məsələyə mən baxmıram ümumiyyətlə nadir işdir deyəsən siz başqa yerə gedin\",\n",
    "    \"salam mən müvəqqəti qeydiyyat üçün sənəd almaq istəyirəm çünki evimi dəyişmişəm xanım bu qeydiyyat məsələsi bizlik deyil icra hakimiyyətinə getməlisiniz biz heç nə etmirik belə məsələdə\",\n",
    "    \"salam mən şəxsiyyət vəsiqəmi itirmişəm ona görə bank sənədi ala bilmirəm nə etməliyəm buyurun bu barədə heç nə deyə bilmərəm xanım bəlkə banka zəng edin biz burda belə sənədlə kömək edə bilmirik\",\n",
    "    \"salam mən mehkum olmamaq arayışı almaq istəyirəm deyiblər sənəd hazırdır amma hələ zəng gəlməyib xanım biz burdan belə məlumatları vermirik gözləyin zəng edərlər mənlik deyil\",\n",
    "    \"salam mən ailə vəziyyətimlə bağlı sənəd təqdim etməliyəm əcnəbi vətəndaş üçün bu asan xidmətdə olurmu xanım bilmirəm valla əcnəbilərlə bağlı çox şey dəyişib siz miqrasiya xidmətinə zəng edin bu bizlik deyil\",\n",
    "    \"salam şəxsiyyət vəsiqəmi dəyişdirməliyəm çünki evlənmişəm və soyadım dəyişib xanım onu biz etmirik deyəsən evlilik aktı lazım olacaq notarius ya qeydiyyat yerinə yaxınlaşın bizdə olmur\",\n",
    "]\n",
    "\n",
    "# Create a DataFrame from the synthetic data\n",
    "df_negatives = pd.DataFrame({\n",
    "    \"Transcription\": negative_samples,\n",
    "    \"Label\": 0\n",
    "})\n",
    "\n",
    "# Append to your original DataFrame\n",
    "df_combined = pd.concat([df_transcripts, df_negatives], ignore_index=True)\n",
    "\n",
    "# Optional: Check class balance\n",
    "print(df_combined['Label'].value_counts())\n",
    "\n",
    "# Optional: Save to CSV\n",
    "df_combined.to_csv(\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\".csv\")\n",
    "display(df)\n",
    "print()\n",
    "display(df['Transcription'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df['Transcription'].iloc[110])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "# Model size: 561M params; Tensor type: F32\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-large')\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-large\")\n",
    "\n",
    "# prepare input\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# forward pass\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Model size: 168M params; Tensor type: F32\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "\n",
    "# text = \"Replace me by any text you'd like.\"\n",
    "text = df['Transcription'].iloc[0]\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = output.pooler_output.detach().numpy().squeeze()\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\".csv\")\n",
    "display(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "display(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Using device: {device}\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-uncased').to(device)\n",
    "model.eval()\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for text in df['Transcription']:\n",
    "    # Tokenize and move to device\n",
    "    encoded = tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded)\n",
    "        cls_embedding = output.pooler_output.detach().cpu().numpy().squeeze()  # move back to CPU for numpy\n",
    "        embeddings.append(cls_embedding)\n",
    "\n",
    "X = np.vstack(embeddings)  # Feature matrix\n",
    "y = df['Label'].values      # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Combine embeddings and labels into a DataFrame\n",
    "df_embeddings = pd.DataFrame(X)\n",
    "df_embeddings[\"Label\"] = y  # Append label column\n",
    "\n",
    "# Define output path\n",
    "output_path = r\".csv\"\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "df_embeddings.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Embeddings saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\".csv\")\n",
    "display(df)\n",
    "print()\n",
    "#display(df['Transcription'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\".csv\")\n",
    "#display(df)\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(r\".csv\")\n",
    "\n",
    "# Features and labels\n",
    "X = df.drop(columns=[\"Label\"]).values\n",
    "y = df[\"Label\"].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Define models to evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=1_000, random_state=42))\n",
    "    ]),\n",
    "    \"SVM (RBF)\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC(random_state=42))\n",
    "    ]),\n",
    "    \"K-NN\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", KNeighborsClassifier())\n",
    "    ]),\n",
    "    # RandomForest, GradientBoosting and GaussianNB often work fine without scaling\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔍 Evaluating: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"✅ Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Access your trained model from the pipeline\n",
    "knn_model = models[\"K-NN\"]\n",
    "\n",
    "# Save to file\n",
    "joblib.dump(knn_model, \"/knn_model.pkl\")\n",
    "print(\"✅ K-NN model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# === Load tokenizer and model ===\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-uncased')\n",
    "model.eval()\n",
    "\n",
    "# === Load your trained K-NN model pipeline ===\n",
    "knn_model = joblib.load(\"../knn_model.pkl\")\n",
    "\n",
    "# === Your custom input text ===\n",
    "input_text = \"alo salam mən sənəd almaq istəyirəm xaricə getmək üçün məhküm olmamağım barədə\"\n",
    "\n",
    "# === Step 1: Lowercase (same as training) ===\n",
    "input_text = input_text.lower()\n",
    "\n",
    "# === Step 2: Generate BERT [CLS] embedding ===\n",
    "encoded = tokenizer(input_text, return_tensors='pt', truncation=True, padding=True)\n",
    "with torch.no_grad():\n",
    "    output = model(**encoded)\n",
    "    embedding = output.pooler_output.detach().numpy().squeeze()\n",
    "\n",
    "# === Step 3: Predict using your trained model ===\n",
    "predicted_label = knn_model.predict([embedding])[0]\n",
    "\n",
    "print(f\"🔍 Prediction: {'Yaxşı cavab' if predicted_label == 1 else 'Pis cavab'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import joblib\n",
    "from denoiser import pretrained\n",
    "from denoiser.dsp import convert_audio\n",
    "from stable_whisper import load_model as load_sw_model\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import gradio as gr\n",
    "\n",
    "# ========== Device Setup ==========\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ========== Denoising Model ==========\n",
    "denoise_model = pretrained.dns64().to(device)\n",
    "DEBUG_DIR = \"debug/\"\n",
    "os.makedirs(DEBUG_DIR, exist_ok=True)\n",
    "\n",
    "def denoise_audio(audio_path):\n",
    "    wav, sr = torchaudio.load(audio_path)\n",
    "    wav = convert_audio(wav, sr, denoise_model.sample_rate, denoise_model.chin)\n",
    "    with torch.no_grad():\n",
    "        enhanced = denoise_model(wav.to(device))\n",
    "    enhanced = enhanced.squeeze(0).cpu()\n",
    "    out_path = os.path.join(DEBUG_DIR, f\"denoised_{uuid.uuid4().hex}.wav\")\n",
    "    torchaudio.save(out_path, enhanced, denoise_model.sample_rate)\n",
    "    return out_path\n",
    "\n",
    "# ========== Whisper Model ==========\n",
    "sw_model = load_sw_model(\"large-v3\", device=device)\n",
    "\n",
    "# ========== BERT + K-NN Setup ==========\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "bert_model.eval()\n",
    "\n",
    "knn_model = joblib.load(\"../knn_model.pkl\")\n",
    "\n",
    "def classify_transcription(text):\n",
    "    text = text.lower()\n",
    "    encoded = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    encoded = {k: v.to(device) for k, v in encoded.items()} # work on both GPU and CPU.\n",
    "    with torch.no_grad():\n",
    "        output = bert_model(**encoded)\n",
    "        embedding = output.pooler_output.detach().numpy().squeeze()\n",
    "    \n",
    "    encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "    with torch.no_grad():\n",
    "        output = bert_model(**encoded)\n",
    "\n",
    "    \n",
    "    prediction = knn_model.predict([embedding])[0]\n",
    "    label = \"Yaxşı cavab ✅\" if prediction == 1 else \"Pis cavab ❌\"\n",
    "    return label\n",
    "\n",
    "# ========== Full Processing Pipeline ==========\n",
    "def process_audio_and_classify(audio_path):\n",
    "    # 1. Save original\n",
    "    raw_copy = os.path.join(DEBUG_DIR, f\"original_{uuid.uuid4().hex}.wav\")\n",
    "    shutil.copy(audio_path, raw_copy)\n",
    "\n",
    "    # 2. Denoise\n",
    "    denoised_path = denoise_audio(audio_path)\n",
    "\n",
    "    # 3. Transcribe\n",
    "    result = sw_model.transcribe(denoised_path, language=\"azerbaijani\", word_timestamps=False)\n",
    "    full_text = result.text.strip()\n",
    "\n",
    "    # 4. Classify\n",
    "    label = classify_transcription(full_text)\n",
    "\n",
    "    # 5. Build HTML output\n",
    "    html = f\"\"\"\n",
    "    <h3>🔊 Denoised Audio</h3>\n",
    "    <audio controls src='{denoised_path}' style='width:100%; margin-bottom:16px;'></audio>\n",
    "    <h3>📄 Transcription</h3>\n",
    "    <div style='white-space: pre-wrap; border:1px solid #ccc; padding:8px;'>{full_text}</div>\n",
    "    <h3>🤖 Model Prediction</h3>\n",
    "    <div style='font-size: 1.2em; font-weight: bold; color: {\"green\" if \"Yaxşı\" in label else \"red\"}'>{label}</div>\n",
    "    \"\"\"\n",
    "    return html\n",
    "\n",
    "# ========== Gradio UI ==========\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## PoC: Evaluating Call Center Operator Performance via Call Analysis\")\n",
    "    audio_input = gr.Audio(type=\"filepath\", label=\"Upload WAV audio\")\n",
    "    output_html = gr.HTML()\n",
    "    run_button = gr.Button(\"Process and Classify\")\n",
    "\n",
    "    run_button.click(\n",
    "        fn=process_audio_and_classify,\n",
    "        inputs=audio_input,\n",
    "        outputs=output_html\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (LLM)",
   "language": "python",
   "name": "llm-py311"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
