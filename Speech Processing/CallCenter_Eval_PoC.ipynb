{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Transcribing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from stable_whisper import load_model\n",
    "\n",
    "# === SETTINGS ===\n",
    "root_dir = r\"...\"\n",
    "output_csv = r\"...\"  # ✅ Save here\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"🚀 Using device: {device}\")\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "model = load_model(\"large-v3\", device=device)\n",
    "\n",
    "# === HELPER FUNCTION ===\n",
    "def transcribe_audio_files(directory):\n",
    "    results = []\n",
    "\n",
    "    # Walk through all subdirectories\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            if filename.lower().endswith(\".wav\"):\n",
    "                filepath = os.path.join(root, filename)\n",
    "                print(f\"🎧 Transcribing: {filepath}\")\n",
    "\n",
    "                try:\n",
    "                    result = model.transcribe(filepath, language=\"az\")\n",
    "                    text = result.text.strip()  # ✅ Access object attribute, not dict\n",
    "\n",
    "                    if text:  # Skip empty transcriptions\n",
    "                        results.append([text, 1])  # Dummy label '1'\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️ Failed to transcribe {filename}: {e}\")\n",
    "    return results\n",
    "\n",
    "# === PROCESS ===\n",
    "transcriptions = transcribe_audio_files(root_dir)\n",
    "\n",
    "# === SAVE TO CSV ===\n",
    "if transcriptions:\n",
    "    os.makedirs(os.path.dirname(output_csv), exist_ok=True)  # ✅ Ensure output dir exists\n",
    "\n",
    "    with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow([\"Transcription\", \"Label\"])  # Header\n",
    "        writer.writerows(transcriptions)\n",
    "\n",
    "    print(f\"✅ Transcriptions saved to {output_csv}\")\n",
    "else:\n",
    "    print(\"❌ No transcriptions were generated.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Single-Audio Transcrabing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import torch\n",
    "from stable_whisper import load_model\n",
    "\n",
    "# === SETTINGS ===\n",
    "audio_path = r\".wav\"\n",
    "output_csv = r\".csv\"\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"🚀 Using device: {device}\")\n",
    "\n",
    "# === LOAD MODEL ===\n",
    "model = load_model(\"large-v3\", device=device)\n",
    "\n",
    "# === TRANSCRIBE SINGLE AUDIO ===\n",
    "try:\n",
    "    print(f\"🎧 Transcribing: {audio_path}\")\n",
    "    result = model.transcribe(audio_path, language=\"az\")\n",
    "    text = result.text.strip()\n",
    "\n",
    "    if text:\n",
    "        # === SAVE TO CSV ===\n",
    "        with open(output_csv, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.writer(file)\n",
    "            writer.writerow([\"Transcription\", \"Label\"])  # Header\n",
    "            writer.writerow([text, 1])  # Dummy label\n",
    "\n",
    "        print(f\"✅ Transcription saved to {output_csv}\")\n",
    "    else:\n",
    "        print(\"⚠️ Transcription is empty.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error during transcription: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\".csv\")\n",
    "display(df)\n",
    "print()\n",
    "display(df['Transcription'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Data Preprocessing & Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\".csv\")\n",
    "display(df)\n",
    "print()\n",
    "display(df['Transcription'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df['Transcription'].iloc[97])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Lowercase the transcription text\n",
    "df[\"Transcription\"] = df[\"Transcription\"].str.lower()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Save the new version to a separate CSV\n",
    "lowercased_file_path = r\"C:\\Pasha-PoC\\transcriptions.csv\"\n",
    "df.to_csv(lowercased_file_path, index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = df.drop(index=13).reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Existing DataFrame\n",
    "df_transcripts = pd.read_csv(r\".csv\")\n",
    "\n",
    "# Pasting synthetic transcriptions here as a list of strings\n",
    "negative_samples = [\n",
    "    \"alo salam mən xaricə getmək üçün məhküm olmamağım barədə sənəd lazım olduğunu dedilər onu asan xidmətdən ala bilərəmmi salam xanım bu məsələyə biz baxmırıq deyəsən başqa yerdə verirlər belə sənədləri məncə siz notariusa yaxınlaşın amma deyiblər ki asan verir elə sənədi məncə əvvəllər verirdi indi dəyişib dəqiq bilmirəm bir dəqiqə zəhmət olmasa gözləyin alo səsiniz gəlmir zəifdi mən də yaxşı başa düşmürəm nə istəyirsiz sənədi bir də zəng edin bəlkə başqa əməkdaş cavab verə bilər\",\n",
    "    \"salam mənim şəxsiyyət vəsiqəmin müddəti keçib onu dəyişmək üçün nə etməliyəm salam buyurun sizə deyiblər biz dəyişirik deyəsən amma indi olmur elə şey bizdə yəni məlumat yoxdur məndə sənəd lazımdı amma nə sənədi bilmirəm dəqiq belə deyiblər sadəcə şəxsiyyət vəsiqəsi üçün adı dəyişib deyiblər onda notarius baxar deyəsən bizdə olmur sənəd vermə proseduru mənlik deyil zəhmət olmasa sonra zəng edin başqa əməkdaş bilər\",\n",
    "    \"salam mən ev üçün qeydiyyat arayışı almaq istəyirdim deyiblər asan xidmətdən alınır xanım o qeydiyyatla bağlı sənədlər biz vermirik məncə icra hakimiyyəti baxır ona yox mən konkret soruşuram siz vermirsinizsə deyin mən gedim başqa yerə baxın google yazın görün hardan verilir bizdə olmur bu gün o sənəd deyəsən çıxarılmır sistemdə problem var başqa sualınız varsa buyurun\",\n",
    "    \"alo salam mən mehkum olmamağım barədə arayış almaq istəyirəm çünki xaricə sənəd təqdim etməliyəm onu haradan ala bilərəm salam xanım dəqiq deyə bilmərəm vallah bizdə olmur məncə ədliyyə baxır o sənədlərə bəlkə ora gedəsiniz amma bu asan xidmət deyilmi siz verməlisiz axı məncə əvvəllər verilirdi indi necədi bilmirəm zəng edin soruşun ya başqa əməkdaşa yönləndirilsin bir dəqiqə alo səs kəsilir sonra zəng edin yaxşı\",\n",
    "    \"salam mən uşağın doğum haqqında şəhadətnaməsini almaq istəyirəm onlayn müraciət etmişdim amma alınmadı onu necə ala bilərəm salam bizdə o sistem işləmir deyəsən indi siz gedin notariusa bəlkə onlar kömək edə bilər onlayn alınmadısa bəlkə sistemdə nasazlıq var mən burada heç nə görə bilmirəm yəni siz deyirsiniz ki asan xidmət vermir məncə əvvəllər verirdi amma indi dəqiq bilmirəm sizə düzgün deyə bilmərəm\",\n",
    "    \"alo salam mən xaricə getmək üçün sənədlər toplamalıyam və məhküm olmamağım barədə arayış lazımdır onu necə ala bilərəm salam xanım belə sənədləri biz vermirik deyəsən yəni siz deyirsiniz heç vermirsiniz əvvəllər demişdilər sizdə olurdu indi yox deyəsən dəyişib sistemdə görünmür mənlik deyil siz gedin notariusa ora verə bilər amma dəqiq deyə bilmərəm yaxşı başa düşmədim indi siz verirsiniz ya yox yox yox deyəsən biz vermirik zəhmət olmasa sonra zəng edin bəlkə başqa əməkdaş bilər\",\n",
    "    \"salam mənə şəxsiyyət vəsiqəsi üçün qeydiyyat arayışı lazımdır internetdə yazılıb asan xidmətdən götürülür buyurun xanım mən bir şey bilmirəm o arayış bəlkə bələdiyyədən alınır yəni bu barədə məlumatım yoxdur bizdə olmur məncə amma siz deyirsiniz ki internetdə yazılıb bura verilir bəli amma mənlik deyil yəni sistemdə baxmıram mən indi sənədi hardan alım deyirsiniz heç bilmirsiniz zəng edin sabah soruşun mən dəqiq deyə bilmirəm\",\n",
    "    \"alo mən vərəsəliklə bağlı sənəd almaq istəyirdim buyurun salam xanım bu barədə heç məlumatım yoxdur vərəsəlik dediniz notarius baxır bizdə olmur sənədi necə ala bilərəm deyirlər bura yaxınlaşmaq lazımdır yox xanım o prosedur bizlik deyil deyəsən məhkəməyə aidiyyatı var zəng edin məhkəməyə bura belə şeylərlə məşğul olmur\",\n",
    "    \"salam mənim adım dəyişib şəxsiyyət vəsiqəsini dəyişmək istəyirəm hansı sənədlər lazımdır xanım siz yəqin qeydiyyat yerinə getməlisiniz bizdə olmur sənəd yəni məlumatım yoxdur belə şeylərlə biz baxmırıq əvvəlcə deyirdilər burdan alınır indi yox notarius bəlkə bilir zəhmət olmasa ora gedin mənlik deyil\",\n",
    "    \"salam mən xaricə sənəd göndərmək istəyirəm və sənədi təsdiqlətməliyəm buyurun amma xanım bu məsələ ilə məşğul olmuruq belə təsdiq üçün siz başqa yerdə təsdiq alın bəlkə konsulluğa zəng edin bu işlər bizlik deyil\",\n",
    "    \"salam mən şəxsiyyət vəsiqəmi itirmişəm və yeni sənəd almaq istəyirəm bu mümkünmü xanım itkin sənədlə bağlı biz məlumat vermirik polisə müraciət edin o sənəd bizlik deyil yəni siz heç nə edə bilmirsiniz yox xanım keçin bölməyə\",\n",
    "    \"alo salam mən ailə vəziyyətimlə bağlı sənəd istəyirəm deyiblər asan verir onu xanım mən bilmirəm belə şeylər üçün notarius var deyəsən ailə arayışları biz vermirik valla məlumatım yoxdur zəng edin başqa yerə\",\n",
    "    \"salam mənim uşağım üçün doğum şəhadətnaməsini bərpa etdirmək istəyirəm sistemdə görünmür xanım biz belə məlumatlara baxmırıq siz qeydiyyat şöbəsinə getməlisiniz bizdə olmur sənəd mən də buradan nə edə bilərəm\",\n",
    "    \"salam mən ev sənədimi təsdiqlətmək istəyirəm yəni alqı-satqı üçün lazımdır buyurun amma xanım bizdə belə şeylər olmur o sənədi siz ya notariusdan alın ya daşınmaz əmlak ofisinə yaxınlaşın asan baxmır bu tip şeylərə\",\n",
    "    \"salam mən özümə vasiqə çıxartmaq istəyirəm amma deyiblər bəzi sənədlər lazımdır nə lazımdır deyə bilərsiniz xanım bu məsələyə mən baxmıram ümumiyyətlə nadir işdir deyəsən siz başqa yerə gedin\",\n",
    "    \"salam mən müvəqqəti qeydiyyat üçün sənəd almaq istəyirəm çünki evimi dəyişmişəm xanım bu qeydiyyat məsələsi bizlik deyil icra hakimiyyətinə getməlisiniz biz heç nə etmirik belə məsələdə\",\n",
    "    \"salam mən şəxsiyyət vəsiqəmi itirmişəm ona görə bank sənədi ala bilmirəm nə etməliyəm buyurun bu barədə heç nə deyə bilmərəm xanım bəlkə banka zəng edin biz burda belə sənədlə kömək edə bilmirik\",\n",
    "    \"salam mən mehkum olmamaq arayışı almaq istəyirəm deyiblər sənəd hazırdır amma hələ zəng gəlməyib xanım biz burdan belə məlumatları vermirik gözləyin zəng edərlər mənlik deyil\",\n",
    "    \"salam mən ailə vəziyyətimlə bağlı sənəd təqdim etməliyəm əcnəbi vətəndaş üçün bu asan xidmətdə olurmu xanım bilmirəm valla əcnəbilərlə bağlı çox şey dəyişib siz miqrasiya xidmətinə zəng edin bu bizlik deyil\",\n",
    "    \"salam şəxsiyyət vəsiqəmi dəyişdirməliyəm çünki evlənmişəm və soyadım dəyişib xanım onu biz etmirik deyəsən evlilik aktı lazım olacaq notarius ya qeydiyyat yerinə yaxınlaşın bizdə olmur\",\n",
    "]\n",
    "\n",
    "# Create a DataFrame from the synthetic data\n",
    "df_negatives = pd.DataFrame({\n",
    "    \"Transcription\": negative_samples,\n",
    "    \"Label\": 0\n",
    "})\n",
    "\n",
    "# Append to your original DataFrame\n",
    "df_combined = pd.concat([df_transcripts, df_negatives], ignore_index=True)\n",
    "\n",
    "# Optional: Check class balance\n",
    "print(df_combined['Label'].value_counts())\n",
    "\n",
    "# Optional: Save to CSV\n",
    "df_combined.to_csv(\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\".csv\")\n",
    "display(df)\n",
    "print()\n",
    "display(df['Transcription'].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df['Transcription'].iloc[110])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "from torch import Tensor\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "\n",
    "def average_pool(last_hidden_states: Tensor,\n",
    "                 attention_mask: Tensor) -> Tensor:\n",
    "    last_hidden = last_hidden_states.masked_fill(~attention_mask[..., None].bool(), 0.0)\n",
    "    return last_hidden.sum(dim=1) / attention_mask.sum(dim=1)[..., None]\n",
    "\n",
    "\n",
    "# Each input text should start with \"query: \" or \"passage: \", even for non-English texts.\n",
    "# For tasks other than retrieval, you can simply use the \"query: \" prefix.\n",
    "input_texts = ['query: Qadınlar gündə nə qədər protein qəbul etməlidir?',\n",
    "                'query: Balqabağın ev şəraitində hazırlanması üsulları',\n",
    "               \"passage: Ümumi olaraq, 19-70 yaş arası qadınlar üçün gündəlik protein tələbatı təxminən 46 qramdır. Əgər hamilədirsinizsə və ya idmanla məşğul olursunuzsa, bu miqdar daha yüksək ola bilər.\",\n",
    "               \"passage: 1. Sıyıq balqabaq: Balqabağı soyub rəndələyin, azca yağda qızardın, duz və şəkər əlavə edib bişirin. 2. Soğanlı balqabaq qovurması: Balqabaq dilimlərini yağda soğanla birlikdə qovurun, dadına duz vurun.\"]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('intfloat/multilingual-e5-large')\n",
    "model = AutoModel.from_pretrained('intfloat/multilingual-e5-large')\n",
    "\n",
    "# Tokenize the input texts\n",
    "batch_dict = tokenizer(input_texts, max_length=512, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "outputs = model(**batch_dict)\n",
    "embeddings = average_pool(outputs.last_hidden_state, batch_dict['attention_mask'])\n",
    "\n",
    "# normalize embeddings\n",
    "embeddings = F.normalize(embeddings, p=2, dim=1)\n",
    "scores = (embeddings[:2] @ embeddings[2:].T) * 100\n",
    "print(scores.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great — the output looks exactly as expected, and here's how to **interpret the results** of the similarity matrix:\n",
    "\n",
    "```python\n",
    "[[86.88, 74.45],\n",
    " [75.53, 84.32]]\n",
    "```\n",
    "\n",
    "Each row corresponds to a **query**, and each column to a **passage**. So, the matrix shows:\n",
    "\n",
    "|                   | Passage 1 (protein) | Passage 2 (pumpkin) |\n",
    "| ----------------- | ------------------- | ------------------- |\n",
    "| Query 1 (protein) | **86.88**           | 74.45               |\n",
    "| Query 2 (pumpkin) | 75.53               | **84.32**           |\n",
    "\n",
    "---\n",
    "\n",
    "✅ Interpretation:\n",
    "\n",
    "* **Query 1:** “Qadınlar gündə nə qədər protein qəbul etməlidir?”\n",
    "\n",
    "  * Highest match is **Passage 1**, with score **86.88** — ✔️ Correct (it's the protein info).\n",
    "* **Query 2:** “Balqabağın ev şəraitində hazırlanması üsulları”\n",
    "\n",
    "  * Highest match is **Passage 2**, with score **84.32** — ✔️ Correct (it's the pumpkin recipe).\n",
    "\n",
    "---\n",
    "\n",
    "✅ Conclusion:\n",
    "\n",
    "* The model **correctly matched Azerbaijani queries** with relevant Azerbaijani passages based on semantic meaning.\n",
    "* This validates that `intfloat/multilingual-e5-large` can perform **cross-language and in-language semantic retrieval** very well — even for **low-resource languages** like Azerbaijani."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "\n",
    "# Model size: 561M params; Tensor type: F32\n",
    "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-large')\n",
    "model = AutoModelForMaskedLM.from_pretrained(\"xlm-roberta-large\")\n",
    "\n",
    "# prepare input\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "# forward pass\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Model size: 168M params; Tensor type: F32\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "model = BertModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "\n",
    "# text = \"Replace me by any text you'd like.\"\n",
    "text = df['Transcription'].iloc[0]\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = output.pooler_output.detach().numpy().squeeze()\n",
    "embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\".csv\")\n",
    "display(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates().reset_index(drop=True)\n",
    "display(df)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "\n",
    "# Check for GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"🚀 Using device: {device}\")\n",
    "\n",
    "# Load model and tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-uncased').to(device)\n",
    "model.eval()\n",
    "\n",
    "embeddings = []\n",
    "\n",
    "for text in df['Transcription']:\n",
    "    # Tokenize and move to device\n",
    "    encoded = tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(**encoded)\n",
    "        cls_embedding = output.pooler_output.detach().cpu().numpy().squeeze()  # move back to CPU for numpy\n",
    "        embeddings.append(cls_embedding)\n",
    "\n",
    "X = np.vstack(embeddings)  # Feature matrix\n",
    "y = df['Label'].values      # Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Combine embeddings and labels into a DataFrame\n",
    "df_embeddings = pd.DataFrame(X)\n",
    "df_embeddings[\"Label\"] = y  # Append label column\n",
    "\n",
    "# Define output path\n",
    "output_path = r\".csv\"\n",
    "\n",
    "# Ensure directory exists\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "\n",
    "# Save to CSV\n",
    "df_embeddings.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"✅ Embeddings saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\".csv\")\n",
    "display(df)\n",
    "print()\n",
    "#display(df['Transcription'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\".csv\")\n",
    "#display(df)\n",
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(r\".csv\")\n",
    "\n",
    "# Features and labels\n",
    "X = df.drop(columns=[\"Label\"]).values\n",
    "y = df[\"Label\"].values\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "\n",
    "# Define models to evaluate\n",
    "models = {\n",
    "    \"Logistic Regression\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", LogisticRegression(max_iter=1_000, random_state=42))\n",
    "    ]),\n",
    "    \"SVM (RBF)\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", SVC(random_state=42))\n",
    "    ]),\n",
    "    \"K-NN\": Pipeline([\n",
    "        (\"scaler\", StandardScaler()),\n",
    "        (\"clf\", KNeighborsClassifier())\n",
    "    ]),\n",
    "    # RandomForest, GradientBoosting and GaussianNB often work fine without scaling\n",
    "    \"Random Forest\": RandomForestClassifier(random_state=42),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(random_state=42),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n🔍 Evaluating: {name}\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"✅ Accuracy: {acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Access your trained model from the pipeline\n",
    "knn_model = models[\"K-NN\"]\n",
    "\n",
    "# Save to file\n",
    "joblib.dump(knn_model, \"/knn_model.pkl\")\n",
    "print(\"✅ K-NN model saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "# === Load tokenizer and model ===\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-multilingual-uncased')\n",
    "model.eval()\n",
    "\n",
    "# === Load your trained K-NN model pipeline ===\n",
    "knn_model = joblib.load(\"../knn_model.pkl\")\n",
    "\n",
    "# === Your custom input text ===\n",
    "input_text = \"alo salam mən sənəd almaq istəyirəm xaricə getmək üçün məhküm olmamağım barədə\"\n",
    "\n",
    "# === Step 1: Lowercase (same as training) ===\n",
    "input_text = input_text.lower()\n",
    "\n",
    "# === Step 2: Generate BERT [CLS] embedding ===\n",
    "encoded = tokenizer(input_text, return_tensors='pt', truncation=True, padding=True)\n",
    "with torch.no_grad():\n",
    "    output = model(**encoded)\n",
    "    embedding = output.pooler_output.detach().numpy().squeeze()\n",
    "\n",
    "# === Step 3: Predict using your trained model ===\n",
    "predicted_label = knn_model.predict([embedding])[0]\n",
    "\n",
    "print(f\"🔍 Prediction: {'Yaxşı cavab' if predicted_label == 1 else 'Pis cavab'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import joblib\n",
    "from denoiser import pretrained\n",
    "from denoiser.dsp import convert_audio\n",
    "from stable_whisper import load_model as load_sw_model\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import gradio as gr\n",
    "\n",
    "# ========== Device Setup ==========\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ========== Denoising Model ==========\n",
    "denoise_model = pretrained.dns64().to(device)\n",
    "DEBUG_DIR = \"debug/\"\n",
    "os.makedirs(DEBUG_DIR, exist_ok=True)\n",
    "\n",
    "def denoise_audio(audio_path):\n",
    "    wav, sr = torchaudio.load(audio_path)\n",
    "    wav = convert_audio(wav, sr, denoise_model.sample_rate, denoise_model.chin)\n",
    "    with torch.no_grad():\n",
    "        enhanced = denoise_model(wav.to(device))\n",
    "    enhanced = enhanced.squeeze(0).cpu()\n",
    "    out_path = os.path.join(DEBUG_DIR, f\"denoised_{uuid.uuid4().hex}.wav\")\n",
    "    torchaudio.save(out_path, enhanced, denoise_model.sample_rate)\n",
    "    return out_path\n",
    "\n",
    "# ========== Whisper Model ==========\n",
    "sw_model = load_sw_model(\"large-v3\", device=device)\n",
    "\n",
    "# ========== BERT + K-NN Setup ==========\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "bert_model.eval()\n",
    "\n",
    "knn_model = joblib.load(\"../knn_model.pkl\")\n",
    "\n",
    "def classify_transcription(text):\n",
    "    text = text.lower()\n",
    "    encoded = tokenizer(text, return_tensors='pt', truncation=True, padding=True)\n",
    "    encoded = {k: v.to(device) for k, v in encoded.items()} # work on both GPU and CPU.\n",
    "    with torch.no_grad():\n",
    "        output = bert_model(**encoded)\n",
    "        embedding = output.pooler_output.detach().numpy().squeeze()\n",
    "    \n",
    "    encoded = {k: v.to(device) for k, v in encoded.items()}\n",
    "    with torch.no_grad():\n",
    "        output = bert_model(**encoded)\n",
    "\n",
    "    \n",
    "    prediction = knn_model.predict([embedding])[0]\n",
    "    label = \"Yaxşı cavab ✅\" if prediction == 1 else \"Pis cavab ❌\"\n",
    "    return label\n",
    "\n",
    "# ========== Full Processing Pipeline ==========\n",
    "def process_audio_and_classify(audio_path):\n",
    "    # 1. Save original\n",
    "    raw_copy = os.path.join(DEBUG_DIR, f\"original_{uuid.uuid4().hex}.wav\")\n",
    "    shutil.copy(audio_path, raw_copy)\n",
    "\n",
    "    # 2. Denoise\n",
    "    denoised_path = denoise_audio(audio_path)\n",
    "\n",
    "    # 3. Transcribe\n",
    "    result = sw_model.transcribe(denoised_path, language=\"azerbaijani\", word_timestamps=False)\n",
    "    full_text = result.text.strip()\n",
    "\n",
    "    # 4. Classify\n",
    "    label = classify_transcription(full_text)\n",
    "\n",
    "    # 5. Build HTML output\n",
    "    html = f\"\"\"\n",
    "    <h3>🔊 Denoised Audio</h3>\n",
    "    <audio controls src='{denoised_path}' style='width:100%; margin-bottom:16px;'></audio>\n",
    "    <h3>📄 Transcription</h3>\n",
    "    <div style='white-space: pre-wrap; border:1px solid #ccc; padding:8px;'>{full_text}</div>\n",
    "    <h3>🤖 Model Prediction</h3>\n",
    "    <div style='font-size: 1.2em; font-weight: bold; color: {\"green\" if \"Yaxşı\" in label else \"red\"}'>{label}</div>\n",
    "    \"\"\"\n",
    "    return html\n",
    "\n",
    "# ========== Gradio UI ==========\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## PoC: Evaluating Call Center Operator Performance via Call Analysis\")\n",
    "    audio_input = gr.Audio(type=\"filepath\", label=\"Upload WAV audio\")\n",
    "    output_html = gr.HTML()\n",
    "    run_button = gr.Button(\"Process and Classify\")\n",
    "\n",
    "    run_button.click(\n",
    "        fn=process_audio_and_classify,\n",
    "        inputs=audio_input,\n",
    "        outputs=output_html\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3CX Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "import torchaudio\n",
    "import joblib\n",
    "from denoiser import pretrained\n",
    "from denoiser.dsp import convert_audio\n",
    "from stable_whisper import load_model as load_sw_model\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import gradio as gr\n",
    "from watchdog.observers import Observer\n",
    "from watchdog.events import FileSystemEventHandler\n",
    "import threading\n",
    "import time\n",
    "import webbrowser\n",
    "\n",
    "import os\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = str(os.cpu_count())\n",
    "\n",
    "# ========== Device Setup ==========\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ========== Folders Setup ==========\n",
    "DEBUG_DIR = \"debug/\"\n",
    "os.makedirs(DEBUG_DIR, exist_ok=True)\n",
    "RECORDER_DIR = \"records\"\n",
    "os.makedirs(RECORDER_DIR, exist_ok=True)\n",
    "PROCESSED_DIR = os.path.join(RECORDER_DIR, \"processed\")\n",
    "os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
    "\n",
    "# ========== Denoising Model ==========\n",
    "denoise_model = pretrained.dns64().to(device)\n",
    "def denoise_audio(audio_path):\n",
    "    wav, sr = torchaudio.load(audio_path)\n",
    "    wav = convert_audio(wav, sr, denoise_model.sample_rate, denoise_model.chin)\n",
    "    with torch.no_grad():\n",
    "        enhanced = denoise_model(wav.to(device))\n",
    "    enhanced = enhanced.squeeze(0).cpu()\n",
    "    out_path = os.path.join(DEBUG_DIR, f\"denoised_{uuid.uuid4().hex}.wav\")\n",
    "    torchaudio.save(out_path, enhanced, denoise_model.sample_rate)\n",
    "    return out_path\n",
    "\n",
    "# ========== Whisper Model ==========\n",
    "sw_model = load_sw_model(\"large-v3\", device=device)\n",
    "\n",
    "# ========== BERT + K-NN Setup ==========\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "bert_model = BertModel.from_pretrained(\"bert-base-multilingual-uncased\")\n",
    "bert_model.eval()\n",
    "bert_model.to(device)\n",
    "\n",
    "knn_model = joblib.load(\"C:/Pasha-PoC/knn_model.pkl\")\n",
    "\n",
    "def classify_transcription(text):\n",
    "    text = text.lower()\n",
    "    encoded = tokenizer(text, return_tensors='pt', truncation=True, padding=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = bert_model(**encoded.to(device))\n",
    "        embedding = output.pooler_output.detach().cpu().numpy().squeeze()\n",
    "    prediction = knn_model.predict([embedding])[0]\n",
    "    label = \"Yaxşı cavab ✅\" if prediction == 1 else \"Pis cavab ❌\"\n",
    "    return label\n",
    "\n",
    "# ========== Full Processing Pipeline ==========\n",
    "def process_audio_and_classify(audio_path):\n",
    "    # 1. Save original\n",
    "    raw_copy = os.path.join(DEBUG_DIR, f\"original_{uuid.uuid4().hex}.wav\")\n",
    "    shutil.copy(audio_path, raw_copy)\n",
    "\n",
    "    # 2. Denoise\n",
    "    denoised_path = denoise_audio(audio_path)\n",
    "\n",
    "    # 3. Transcribe\n",
    "    result = sw_model.transcribe(denoised_path, language=\"azerbaijani\", word_timestamps=False)\n",
    "    full_text = result.text.strip()\n",
    "\n",
    "    # 4. Classify\n",
    "    label = classify_transcription(full_text)\n",
    "\n",
    "    # 5. Build HTML output\n",
    "    html = f\"\"\"\n",
    "    <h3>🔊 Denoised Audio</h3>\n",
    "    <audio controls src='{denoised_path}' style='width:100%; margin-bottom:16px;'></audio>\n",
    "    <h3>📄 Transcription</h3>\n",
    "    <div style='white-space: pre-wrap; border:1px solid #ccc; padding:8px;'>{full_text}</div>\n",
    "    <h3>🤖 Model Prediction</h3>\n",
    "    <div style='font-size: 1.2em; font-weight: bold; color: {\"green\" if \"Yaxşı\" in label else \"red\"}'>{label}</div>\n",
    "    \"\"\"\n",
    "    return html\n",
    "\n",
    "# === File Watcher Setup ===\n",
    "class NewWavHandler(FileSystemEventHandler):\n",
    "    def on_created(self, event):\n",
    "        if event.is_directory or not event.src_path.endswith(\".wav\"):\n",
    "            return\n",
    "        if \"processed\" in os.path.normpath(event.src_path).split(os.sep):\n",
    "            return  # ✅ Skip files inside any \"processed\" folder\n",
    "    \n",
    "        print(f\"[Watcher] Detected new file: {event.src_path}\")\n",
    "        \n",
    "        try:\n",
    "            # Run full processing\n",
    "            result_html = process_audio_and_classify(event.src_path)\n",
    "            print(\"[Watcher] Processing complete.\")\n",
    "\n",
    "            # Save result to HTML\n",
    "            result_filename = f\"result_{uuid.uuid4().hex}.html\"\n",
    "            result_path = os.path.join(DEBUG_DIR, result_filename)\n",
    "            with open(result_path, \"w\", encoding=\"utf-8\") as f:\n",
    "                f.write(result_html)\n",
    "            print(f\"[Watcher] Result saved to: {result_path}\")\n",
    "\n",
    "            # Open in browser\n",
    "            webbrowser.open(f\"file://{os.path.abspath(result_path)}\")\n",
    "\n",
    "            # Move original file to processed/\n",
    "            relative_path = os.path.relpath(event.src_path, RECORDER_DIR)\n",
    "            processed_path = os.path.join(PROCESSED_DIR, relative_path)\n",
    "\n",
    "            os.makedirs(os.path.dirname(processed_path), exist_ok=True)\n",
    "            shutil.move(event.src_path, processed_path)\n",
    "            print(f\"[Watcher] Moved file to: {processed_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[Watcher] Error processing file: {e}\")\n",
    "\n",
    "def start_file_watcher():\n",
    "    observer = Observer()\n",
    "    event_handler = NewWavHandler()\n",
    "    observer.schedule(event_handler, path=RECORDER_DIR, recursive=True)\n",
    "    observer.start()\n",
    "    print(\"[Watcher] Monitoring started.\")\n",
    "    try:\n",
    "        while True:\n",
    "            time.sleep(1)\n",
    "    except KeyboardInterrupt:\n",
    "        observer.stop()\n",
    "    observer.join()\n",
    "\n",
    "# Start the watcher in a background thread\n",
    "watcher_thread = threading.Thread(target=start_file_watcher, daemon=True)\n",
    "watcher_thread.start()\n",
    "\n",
    "# ========== Gradio UI ==========\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"## PoC: Evaluating Call Center Operator Performance via Call Analysis\")\n",
    "    audio_input = gr.Audio(type=\"filepath\", label=\"Upload WAV audio\")\n",
    "    output_html = gr.HTML()\n",
    "    run_button = gr.Button(\"Process and Classify\")\n",
    "\n",
    "    run_button.click(\n",
    "        fn=process_audio_and_classify,\n",
    "        inputs=audio_input,\n",
    "        outputs=output_html\n",
    "    )\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "WHITESPACE_HANDLER = lambda k: re.sub('\\s+', ' ', re.sub('\\n+', ' ', k.strip()))\n",
    "\n",
    "article_text = \"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model_name = \"csebuetnlp/mT5_multilingual_XLSum\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "input_ids = tokenizer(\n",
    "    [WHITESPACE_HANDLER(article_text)],\n",
    "    return_tensors=\"pt\",\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=512\n",
    ")[\"input_ids\"].to(\"cuda\")\n",
    "\n",
    "output_ids = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    max_length=84,\n",
    "    no_repeat_ngram_size=2,\n",
    "    num_beams=4\n",
    "    # early_stopping=True  # Optional: stop when EOS token is reached\n",
    "    # length_penalty=\n",
    ")[0]\n",
    "\n",
    "summary = tokenizer.decode(\n",
    "    output_ids,\n",
    "    skip_special_tokens=True,\n",
    "    clean_up_tokenization_spaces=False\n",
    ")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**For input**: \"*Salam! Xoş gününüz olsun, “X Bank” müştəri xidmətinə zəng etdiyiniz üçün təşəkkür edirik. Mən Ayseləm. \n",
    "Sizə necə kömək edə bilərəm? Salam, Aysel xanım. Mən kartımın balansını öyrənmək istəyirəm. Əlbəttə, sizə kömək etmək üçün \n",
    "əvvəlcə şəxsiyyətinizi təsdiqləməliyəm. Zəhmət olmasa, adınızı, soyadınızı və doğum tarixinizi qeyd edin. \n",
    "Adım Kamran Məmmədov, 12 iyun 1987-ci il. Təşəkkür edirəm, Kamran bəy. Sistemə baxıram... \n",
    "Bəli, sizi tapdım. Hal-hazırda kartınızın balansı 524 manat 80 qəpik təşkil edir. Çox sağ olun. \n",
    "Bir sualım da var. Kartımda hər ay niyə 2 manat tutulur? Bu kartın aylıq xidmət haqqıdır. \n",
    "Əgər istəsəniz, komissiyasız kart növü ilə əvəz edə bilərik. Bəli, maraqlıdır. \n",
    "Zəhmət olmasa, ətraflı məlumat verin. Əlbəttə! Yeni kartla bağlı sizə məlumat göndərəcəyik və filialımıza yaxınlaşaraq \n",
    "dəyişiklik edə bilərsiniz. Oldu, təşəkkür edirəm. Sizə kömək edə bildiyim üçün məmnunam. Gözəl günlər arzulayıram!*\"\n",
    "\n",
    "**Output is**: \"*X Bankın müştəri xidmətinə zəng etdiyiniz üçün təşəkkür edirik.*\"\n",
    "\n",
    "**For input**: \"*Rusiya Prezidenti Putin sülh danışıqları üçün İstanbula getməyib. \n",
    "Onu Ukrayna ilə danışıqlarda köməkçisi təmsil edir, Kreml açıqlayıb.\n",
    "Putin İstanbula gəlsəydi, ABŞ Prezidenti Donald Trump da bu görüşə qoşulacağını demişdi.\n",
    "Mayın 11-də Putin özü Zelenski ilə sülh danışıqlarına çağırış etmişdi.\n",
    "Zelenski də İstanbulda onu şəxsən gözləyəcəyini demişdi.*\"\n",
    "\n",
    "**Output is**: \"*Rusiya Prezidenti Vladimir Putin Ukrayna prezidenti Volodimir Zelenski ilə sülh danışıqları üçün İstanbula gəlməyib.*\"\n",
    "\n",
    "---\n",
    "\n",
    "### **Summary Conclusion**\n",
    "\n",
    "The `csebuetnlp/mT5_multilingual_XLSum` model demonstrates strong baseline performance for Azerbaijani text summarization, especially in the context of news articles, as evidenced by accurate summaries of political news input. However, its performance on domain-specific data—such as bank call center conversations—shows limitations due to the conversational and transactional nature of the content, which the model wasn't explicitly trained on.\n",
    "\n",
    "This model serves as a **good starting point**, but for effective deployment in the banking customer service domain, **fine-tuning is essential**. A fine-tuning strategy can begin with the **\"LocalDoc/summarization\\_azerbaijan\"** dataset to bridge the domain gap, followed by incorporation of **bank-provided audio recordings**. These recordings can be transcribed using **Whisper-Large-V3**, post-processed and cleaned with a **large language model (LLM)**, **manually reviewed a sample set** to *validate the LLM corrections* and then used to fine-tune the model for **dialogue-based summarization**.\n",
    "\n",
    "These transcriptions can be used in two complementary ways:\n",
    "\n",
    "* **As-is (noisy STT output):** Fine-tune the summarizer to handle real-world, imperfect input, improving robustness.\n",
    "* **After correction (cleaned by LLM):** Fine-tune on clean data for higher precision and clarity in summaries.\n",
    "\n",
    "Alternatively, **Whisper itself can be fine-tuned** (if needed and feasible) on domain-specific audio to produce **higher-quality transcriptions**, reducing (or eliminating) the need for post-processing before summarization fine-tuning.\n",
    "\n",
    "This approach ensures adaptability to both **raw conversational input** and **high-quality cleaned text**, supporting a production-grade summarization system for banking customer interactions in Azerbaijani. This pipeline ensures the summarization model will learn the structure, terminology, and conversational nuances specific to Azerbaijani banking customer service contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12.3 (CUDA GPU)",
   "language": "python",
   "name": "cuda_gpu_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
